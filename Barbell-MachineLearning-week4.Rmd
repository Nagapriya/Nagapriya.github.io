---
title: "Barbell lifts"
author: "Nagapriya"
date: "May 8, 2017"
output: html_document
---

```{r, include=FALSE, echo=FALSE}
library(caret)
library(dplyr)
library(ggplot2)
library(rattle)
library(randomForest)
```

##Executive Summary
Data collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants performing barbell lifts correctly (classe A) and incorrectly (classe B, C, D, E, F) was provided.
The aim of this assignment is to use this data to determine whether the barbell lifts were performed correctly or not. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

This assignment shows that a Random Forest model can predict the classe variable (which determines the way the lift was performed) with 99% accuracy.

##Reading and Preprocessing Data

Reading Data
```{r}
training<-read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing<-read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
```

Most columns contain only "NA"s. The columens which have only NAs in the testing set were removed in both testing and training sets. Also, the first seven columns do not contain relevant information and were removed.

```{r}
dftest<-data.frame(testing[,1])
colnames(dftest)[1]<-colnames(testing)[1]
dftrain<-data.frame(training[,1])
colnames(dftrain)[1]<-colnames(training)[1]
n<-1
for(i in 2:160)
{
  if(sum(is.na(testing[,i]))<20)
  {
    ##print(i)
    n=n+1
    dftest<-data.frame(dftest,testing[,i])
    colnames(dftest)[n]<-colnames(testing)[i]
    dftrain<-data.frame(dftrain,training[,i])
    colnames(dftrain)[n]<-colnames(training)[i]
  }
}
dftest<-dftest[8:60]
dftrain<-dftrain[8:60]
```

The training dataset was split into initial train (dftrain_ini) and initial test (dftest_ini) datasets. 

```{r}
inTrain<-createDataPartition(dftrain$classe,p=0.6,list=FALSE)
dftrain_ini<-dftrain[inTrain,]
dftest_ini<-dftrain[-inTrain,]
```

##Model Selection
Two models were tried. The first one is the decision tree model.

###Rpart
```{r}
set.seed(233)
modfitrpart <- train(classe ~ .,method='rpart',data=dftrain_ini)
fancyRpartPlot(modfitrpart$finalModel)
predrpart=predict(modfitrpart,newdata=dftest_ini)
CMrpart=confusionMatrix(predrpart,dftest_ini$classe)
CMrpart$overall[1]
```
This model was found to have poor accuracy (`r round(CMrpart$overall[1],2)`). The out of sample error is more than 50%. Hence this model was rejected.


###Random Forest
Fitting a Random Forest model:
```{r}
set.seed(12345)
modfitrf <- randomForest(classe ~ .,method='class',data=dftrain_ini)
predrf=predict(modfitrf,newdata=dftest_ini)
CMrf=confusionMatrix(predrf,dftest_ini$classe)
CMrf$overall[1]
```
The accuracy on the initial test dataset (part of the available training dataset) was `r round(CMrf$overall[1],2)`. Therefore this model was used to predict the "classe" variable of the testing dataset.

##Conclusion and Predicting the testing data
The Random Forest model (as described above) was found to be very accurate with low out of box error rate. 

The prediction on the testing data  was done using the model fit from the Random Forest model above.

```{r}
predtest=predict(modfitrf,newdata=testing)
```

The following is the prediction of the testing data using the fitted random forest model:
`r predtest`
